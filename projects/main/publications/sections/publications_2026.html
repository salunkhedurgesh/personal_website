<div class="year_block">
    <div class="year">
        <p>2026</p>
    </div>

    <div class="paper">
        <div class="paper_description">
            <div>
                <div class="action_row" id="science26_paper">
                    <a href="/projects/main/resources/citations/science26_gupta.bib" target="_blank"><img
                            src="/projects/main/webpage_resources/images/icon_cite_dark.png" alt="cite"></a>
                    <a href="/projects/main/resources/papers/science26_gupta.pdf" target="_blank"><img
                            src="/projects/main/webpage_resources/images/icon_download_dark.png" alt="download"></a>
                    <a onclick="abstractClick('science26_abstract')"><img
                            src="/projects/main/webpage_resources/images/icon_abstract_dark.png" alt="abstract"></a>
                </div>
            </div>

            <div class="paper_title">
                <p class="paper_heading">
                    Demonstrate Once, Execute on Many: Kinematic Intelligence for Cross-robot Skill Transfer</p>
                <p class="authors">
                    Authors: <span style="color: var(--halycon)">Durgesh Haribhau Salunkhe<sup>*</sup></span>, Sthithpragya Gupta<sup>*</sup> and Aude Billard
                    <br>
                        Submitted to: Science Robotics (<span style="color: var(--halycon)">Science</span>), 2026
                    <br>
                    <span style="font-size: 0.95em;">* Equal contribution</span>
                </p>

            </div>
        </div>
        <div id="science26_abstract" style="display: none;" class="abstract">
            <p>
                Teaching robots new skills should be as natural as showing rather than programming. Learning from Demonstration (LfD) moves toward this goal by allowing users to guide a robot or sketch a desired motion, enabling learning without writing a line of code. Yet most LfD methods remain tied to the robot they were trained on. Changes in morphology, different link lengths, joint orientations, or limits often break the learned behaviour, making retraining unavoidable.
                Here we introduce a framework that endows robots with kinematic intelligence: an internal understanding of their own joint limits, singularities, and connectivity. Instead of correcting for these constraints after learning, we embed them directly into the control policy from the outset. The approach takes one or multiple demonstrations, extracts a globally stable dynamical system, and produces behaviours that remain valid across robots with different kinematic structures.
                Our method is grounded in a comprehensive analytical classification of non-cuspidal 3-revolute (3R) arms, which form the building blocks of many industrial manipulators. This classification enables a joint-space policy that preserves user intent while automatically adapting to robot-specific constraints. We validate the framework on a diverse set of simulated and real robots, redundant and non-redundant, with varied link geometries and joint configurations, and show that the demonstrated skill can be executed safely, smoothly, and consistently on all of them.
                By showing how analytical kinematic properties can be leveraged for cross-robot skill transfer, our work moves LfD closer to scalable, intuitive robot teaching for non-experts, enabling safe and reliable deployment without retraining.
            </p>
        </div>
    </div>

</div>